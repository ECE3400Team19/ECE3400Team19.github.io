##IS “A BAN ON OFFENSIVE AUTONOMOUS WEAPONS BEYOND MEANINGFUL HUMAN CONTROL” GOING TO WORK?
##By Team 19 – Asena Ulug, Cynthia Zelga, Laasya Renganathan, John Chukwunonso Nwankwo, Robert Morgowicz

  In March 2014, the Crimean peninsula was annexed from Ukraine by the Russian Federation by military takeover. Ukraine and many world leaders considered it to be a violation of international law. Sanctions were imposed on Russian but the takeover increased Russia’s position in the petroleum regulatory economies, to which it has continued to trade with. In April 2015, the Islamic Republic of Iran got into a joint deal to redesign, convert and reduce its nuclear facilities earning billions of dollars and oil revenue as deal bond, but has continued to be revolutionary in other nuclear designs selling around the world. Today, we are concerned about investing in autonomous weapons for warfare and truth remains that it is only a question of time before waring nations go all out thereby the making the ban impossible because of the stakes in the concept of war.

  On our study case, ‘Musk/Hawking Open Letter On Autonomous Weapons’ which is an open letter from the Artificial Intelligence (AI) and Robotics researchers, we saw that it was concluded that AI has great benefit potential to human in many other ways other than warfare, but the ethical question is, why should we ever consider it for warfare?  It is almost inevitable that wars abound in our world today, as a means of dominance and a means of resolving conflicts between tribes and nations, ethically we would be glad to have conversations like, taking other approaches to produce best outcome for its citizens but we must note that war has never left any nation in a fair condition so why engage in it at all, bringing us to the bigger question of who benefits from these wars in the first place?

  In most warfare cases, as cited in our first paragraph above, we see that disputes leading to war arises from government’s urge to dominate in resilient ways and in most cases end up enriching the stakeholders, gaining regional and political control. Who then are these stakeholders? They are major players in war, nations who continuously seek to gained dominance and profits from war conditions, and would only be question of time (in the near future) before offensive autonomous weapons beyond meaningful human control would help take over their dirty work of war engagement. Today, Jerusalem is waring against Palestine, Syria against its own nation, all in the bid for territorial control and yet the United Nation’s Security Council cannot do much about this because its member councils with veto powers are those engaging in these territorial battle.

  Just as cited in cases of many autonomous cars incidents, where the owners of the cars or drivers are considered priority in the case of a crash, the investors would want to invest in a product that would appeal to the customers – in this case maximum safety, so does many investments and stakeholder prioritize their decisions to maximize profit, to which war and arms dealing are definitely part of it. In conclusion, we would be proud to argue on the contrary that the utilitarian test of what the best ways to engage in war, or the justice test of who the actions of war is fair to, or the virtue test of whether the actions taken reflecting anyone’s image but the truth remains that the subject of the application of AI in war from a stakeholders point of view would make it difficult to enforce the ban on autonomous weapons because the ethical reasoning should first arise from why should there be wars in the first place and since they abound it is only a question of time before the waring nations would go all out.
